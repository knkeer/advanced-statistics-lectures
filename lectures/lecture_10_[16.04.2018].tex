%!TEX root = ../main.tex

\section{Лекция 10}
\begin{proof}[Продолжение доказательства]
	Построим биекцию между $(\matr{Z}^{\top}\vec{X}, \|\vec{X}\|^{2})$ и $(\hat{\vec{\theta}}(\vec{X}), \|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2})$. Заметим, что по теореме Пифагора
	\[
		\|\vec{X}\|^{2} = \|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2} + \|\matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2},
	\]
	так как $\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})$ лежит в $L^{\perp}$, а $\|\matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}$ "--- в $L$. Далее, согласно формуле для оценки методом наименьших квадратов
	\[
		\matr{Z}^{\top}\vec{X} = (\matr{Z}^{\top}\matr{Z})\hat{\vec{\theta}}(\vec{X}).
	\]
	Тем самым, если мы знаем значения пары $(\hat{\vec{\theta}}(\vec{X}), \|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2})$, то мы знаем значения пары $(\matr{Z}^{\top}\vec{X}, \|\vec{X}\|^{2})$ (так как $\matr{Z}$ тоже известна). В обратную сторону всё аналогично:
	\begin{align*}
		\hat{\vec{\theta}}(\vec{X}) 
		&= (\matr{Z}^{\top}\matr{Z})^{-1}\matr{Z}^{\top}\vec{X}, \\
		\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}
		&= \|\vec{X}\|^{2} - \|\matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}.
	\end{align*}
	Тем самым получаем полную взаимообратную связь между парами. Следовательно, $(\hat{\vec{\theta}}(\vec{X}), \|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2})$ есть полная достаточная статистика.
\end{proof}

Теперь рассмотрим некоторые следствия данной теоремы.
\begin{consequence}
	$\hat{\vec{\theta}}(\vec{X})$ есть оптимальная оценка для $\vec{\theta}$, $\matr{Z}\hat{\vec{\theta}}(\vec{X})$ "--- для $\vec{\ell}$, а $\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}/(n - k)$ "--- для $\sigma^{2}$.
\end{consequence}
\begin{proof}
	Ранее было показано, что эти функции являются несмещёнными оценками для соответствующих параметров. Но они все являются функциями от полной и достаточной статистики. Следовательно, они оптимальны.
\end{proof}

\subsection{Доверительные интервалы и области}
Теперь мы бы хотели построить доверительные интервалы для параметров гауссовской линейной регрессии. Но для этого нужна теорема об ортогональных разложениях. Докажем её, но перед этим вспомним, что такое распределение хи-квадрат.
\begin{definition}
	Будем говорить, что случайная величина $\xi$ имеет \emph{распределение хи-квадрат c $n$ степенями свободы}, если её плотность равна
	\[
		p_{\xi}(x) = \frac{x^{n/2 - 1}e^{-x/2}}{2^{n/2}\Gamma(n/2)}\mathbf{1}_{x \geq 0},
	\]
	то есть $\xi \sim \Gamma(n/2, 1/2)$. Обозначение: $\xi \sim \chi^{2}_{n}$.
\end{definition}
Далее вспомним ещё один простой факт: если $\xi_{1}, \ldots, \xi_{n}$ есть независимые и одинаково распределённые случайные величины с стандартным нормальным распределением, то $\xi_{1}^{2} + \ldots + \xi_{n}^{2} \sim \chi^{2}_{n}$. Теперь можно приступать к теореме.
\begin{theorem}[об ортогональных разложениях]
	Пусть $\vec{X} \sim \mathcal{N}(\vec{\ell}, \sigma^{2}\matr{I}_{n})$, а $L_{1} \oplus L_{2} \oplus \ldots \oplus L_{r}$ есть разложение $\mathbb{R}^{n}$ в прямую сумму линейных ортогональных подпространств. Далее, пусть $\vec{Y}_{i}$ есть проекция $\vec{X}$ на $L_{i}$. Тогда $Y_{1}, \ldots, Y_{r}$ независимы в совокупности и 
	\[
		\frac{1}{\sigma^{2}}\|\vec{Y}_{i} - \EE[\vec{Y}_{i}]\|^{2} \sim \chi^{2}_{\operatorname{dim} L_{i}}.
	\]
\end{theorem}
\begin{proof}
	Идея состоит в том, чтобы свести эту теорему к факту, сформулированному выше. Для этого возьмём в $\mathbb{R}^{n}$ ортонормированный базис $\vec{f}_{1}, \ldots, \vec{f}_{n}$ такой, что
	\begin{align*}
		\vec{f}_{1}, \ldots, \vec{f}_{k_{1}} &\text{ "--- базис } L_{1}, \\
		\vec{f}_{k_{1} + 1}, \ldots, \vec{f}_{k_{1} + k_{2}} &\text{ "--- базис } L_{2}, \\
		\vdots \\
		\vec{f}_{k_{1} + \ldots + k_{r - 1} + 1}, \ldots, \vec{f}_{n} &\text{ "--- базис } L_{r}.
	\end{align*}
	В таком случае размерность $L_{i}$ равна $k_{i}$ для всех $i = 1, \ldots, r$. Далее, введём коэффициенты $W_{i} = \langle \vec{X}, \vec{f}_{i} \rangle$ для всех $i = 1, \ldots, n$. Скомпонуем эти коэффициенты в вектор и представим его в виде линейного преобразования $\vec{X}$:
	\[
		\vec{W} = \begin{pmatrix}
			W_{1} \\ \vdots \\ W_{n}
		\end{pmatrix}
		=
		\matr{C}\vec{X},
		\text{ где }
		\matr{C} = \begin{pmatrix}
			\vec{f}_{1}^{\top} \\ \vdots \\ \vec{f}_{n}^{\top}
		\end{pmatrix}.
	\]
	Заметим, что матрица $\matr{C}$ ортогональна, так как её строки задают ортонормированный базис $\mathbb{R}^{n}$. Так как $\vec{X}$ гауссовский, то и $\vec{W}$ тоже будет гауссовским, так как он получается линейным преобразованием. Осталось заметить, что $\vec{W} \sim \mathcal{N}(\matr{C}\vec{\ell}, \sigma^{2}\matr{I}_{n})$, так как $\matr{C}\matr{C}^{\top} = \matr{I}_{n}$. Тем самым компоненты $\vec{W}$ независимы в совокупности. Тогда $\vec{Y}_{i}$, которые считаются следующим образом:
	\[
		\vec{Y}_{j} = W_{k_{1} + \ldots + k_{j - 1} + 1}\vec{f}_{k_{1} + \ldots + k_{j - 1} + 1} + \ldots + W_{k_{1} + \ldots + k_{j}}\vec{f}_{k_{1} + \ldots + k_{j}},
	\]
	тоже будут независимы в совокупности. Теперь докажем свойство про их распределение. Для этого заметим, что для всех $i = 1, \ldots, n$
	\[
		\frac{W_{i} - \EE[W_{i}]}{\sigma} \sim \mathcal{N}(0, 1).
	\]
	В таком случае, так как векторы ортонормированные, то
	\begin{align*}
		\frac{1}{\sigma^{2}}\|\vec{Y}_{j} - \EE[\vec{Y}_{j}]\|^{2}
		&= \left\|\sum_{i = 1}^{k_{j}} \frac{W_{k_{1} + \ldots + k_{j - 1} + i} - \EE[W_{k_{1} + \ldots + k_{j - 1} + i}]}{\sigma}\vec{f}_{k_{1} + \ldots + k_{j - 1} + i}\right\|^{2} \\
		&= \sum_{i = 1}^{k_{j}} \left(\frac{W_{k_{1} + \ldots + k_{j - 1} + i} - \EE[W_{k_{1} + \ldots + k_{j - 1} + i}]}{\sigma}\right)^{2}
		\sim \chi^{2}_{k_{j}}. \qedhere
	\end{align*}
\end{proof}
Теперь выпишем из этого достаточно важное следствие:
\begin{consequence}
	В гауссовской линейной модели $\matr{Z}\hat{\vec{\theta}}(\vec{X})$ (и $\hat{\vec{\theta}}(\vec{X})$) независимо с $\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})$ и
	\begin{align*}
		\frac{1}{\sigma^{2}}\|\matr{Z}\hat{\vec{\theta}}(\vec{X}) - \matr{Z}\vec{\theta}\|^{2} &\sim \chi^{2}_{k}, \\
		\frac{1}{\sigma^{2}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2} &\sim \chi^{2}_{n - k}. 
	\end{align*}
\end{consequence}
\begin{proof}
	Как известно, $\matr{Z}\hat{\vec{\theta}}(\vec{X})$ есть проекция $\vec{X}$ на $L^{\perp}$, а $\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})$ проецирует $\vec{X}$ на $L$. Так как $\mathbb{R}^{n} = L \oplus L^{\perp}$, то применима теорема об ортогональных разложениях. Следовательно, $\matr{Z}\hat{\vec{\theta}}(\vec{X})$ и $\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})$ независимы и верны выражения из условия.
\end{proof}
Теперь приступим к доверительным интервалам. Перед этим надо определить, что это вообще такое.
\begin{definition}
	Пусть $\{\Pr_{\theta} \mid \theta \in \Theta\}$ "--- параметрическое семейство, $\vec{X}$ "--- наблюдение из параметрического распределения $\Pr \in \{\Pr_{\theta} \mid \theta \in \Theta\}$, и параметр $\theta$ одномерный: $\Theta \subseteq \mathbb{R}$. Будем называть пару статистик $(T_{1}(\vec{X}), T_{2}(\vec{X})$ \emph{доверительным интервалом} для $\theta$ с уровнем доверия $\gamma$, если для всех $\theta \in \Theta$
	\[
		\Pr_{\theta}(T_{1}(\vec{X}) < \theta < T_{2}(\vec{X})) \geq \gamma.
	\]
	Если в данном неравенстве всегда достигается равенство, то доверительный интервал называют \emph{точным}.
\end{definition}
Данное определение почти без изменений переносится на многомерный параметр.
\begin{definition}
	Подмножество $S(\vec{X}) \subseteq \Theta$ называется доверительной областью для $\vec{\theta}$ с уровнем доверия $\gamma$, если для всех $\vec{\theta} \in \Theta$
	\[
		\Pr_{\vec{\theta}}(\vec{\theta} \in S(\vec{X})) \geq \gamma.
	\]
\end{definition}

Ну что же, сперва построим доверительный интервал для $\sigma^{2}$. Для этого нужно воспользоваться так называемой центральной статистикой. Дадим определение:
\begin{definition}
	Функция от выборки $S_{\theta}(\vec{X})$, которая может зависеть от параметра $\theta$, называется \emph{центральной статистикой}, если её распределение не зависит от $\theta$.
\end{definition}
Заметим, что в данном случае можно использовать $\sigma^{-2}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}$ в качестве центральной статистики, так как ранее было доказано, что она имеет распределение хи-квадрат с $n - k$ степенями свободы. Пусть $u_{\alpha}$ равно $\alpha$-квантилю $\chi^{2}_{n - k}$. Тогда
\[
	\Pr\left(u_{(1 - \gamma)/2} < \frac{1}{\sigma^{2}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2} < u_{(1 + \gamma)/2}\right) = \gamma.
\]
Следовательно, точный доверительный интервал для $\sigma^{2}$ уровня доверия $\gamma$ имеет вид
\[
	\left[\frac{1}{u_{(1 + \gamma)/2}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}, \frac{1}{u_{(1 - \gamma)/2}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}\right]
\]

Теперь попытаемся определить доверительный интервал для $\theta_{i}$. Для этого заметим, что $\hat{\vec{\theta}}(\vec{X}) \sim \mathcal{N}(\vec{\theta}, \sigma^{2}\matr{A})$, где $\matr{A} = (\matr{Z}^{\top}\matr{Z})^{-1}$. В таком случае 
\[
	\frac{\hat{\theta}_{i} - \theta_{i}}{\sqrt{\sigma^{2}a_{ii}}} \sim \mathcal{N}(0, 1).
\]
Но возникает проблема: всё ещё остаётся $\sigma^{2}$. Что делать? Заменить на оценку. Оказывается, что в гауссовском случае всё остаётся весьма хорошо. Полученная случайная величина будет иметь распределение Стьюдента с $n - k$ степенями свободы:
\[
	\sqrt{\frac{n - k}{a_{ii}}}\frac{\hat{\theta}_{i} - \theta_{i}}{\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|} \sim \mathrm{T}_{n - k}.
\]
Почему это так? Это следует из того, что $\hat{\theta_{i}}$ не зависит от $\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|$, и дробь имеет вид отношения стандартной нормальной случайной величины к корню из случайной величины с распределением хи-квадрат, что и есть распределение Стьюдента по определению.

Пусть $t_{\alpha}$ есть $\alpha$-квантиль распределения Стьюдента $\mathrm{T}_{n - k}$. Так как оно симметрично относительно нуля, то можно сразу записать точный доверительный интервал с уровнем доверия $\gamma$ в следующем виде:
\[
	\hat{\theta}_{i} - t_{(1 + \gamma)/2}\sqrt{\frac{a_{ii}}{n - k}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\| < \theta_{i} < \hat{\theta}_{i} + t_{(1 + \gamma)/2}\sqrt{\frac{a_{ii}}{n - k}}\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|.
\]

Осталось построить доверительную область для $\vec{\theta}$. Здесь возникает третье стандартное распределение, связанное с гауссовским "--- распределение Фишера. 
\begin{definition}
	Пусть $\xi$, $\eta$ "--- независимые случайные величины, причём $\xi \sim \chi^{2}_{k}$, $\eta \sim \chi^{2}_{n}$. Тогда $\delta = \frac{\xi/k}{\eta/n}$ имеет распределение Фишера с $(k, n)$ степенями свободы. Обозначение: $\delta \sim \mathrm{F}_{k, n}$.
\end{definition}
Согласно следствию из теоремы об ортогональных разложениях
\[
	\frac{\|\matr{Z}\hat{\vec{\theta}}(\vec{X}) - \matr{Z}\vec{\theta}\|^{2}}{\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}}\frac{n - k}{k} \sim \mathrm{F}_{k, n - k}.
\]
Далее, пусть $f_{\alpha}$ есть $\alpha$-квантиль распределения $\mathrm{F}_{k, n - k}$. Так как оно неотрицательно, то доверительной областью будет
\[
	S(\vec{X}) = \left\{ \vec{\theta} \in \mathbb{R}^{k} \colon \frac{\|\matr{Z}\hat{\vec{\theta}}(\vec{X}) - \matr{Z}\vec{\theta}\|^{2}}{\|\vec{X} - \matr{Z}\hat{\vec{\theta}}(\vec{X})\|^{2}}\frac{n - k}{k} < f_{\gamma}\right\}.
\]
Стоит заметить, что геометрически доверительная область будет иметь форму эллипсоида.

\subsection{Проверка гипотез}
На этом мы пока что простимся с линейной регрессией и вернёмся к ней несколько позже. Пока что разберёмся с такой вещью, как проверка гипотез. Вообще, проверка гипотез "--- это больше методология, тут математики меньше и важнее понять сам метод. Что вообще предполагается в статистике? Предполагается следующее: если вероятность события крайне мала (меньше, чем $0.01$, например), то в единичном испытании данное событие не происходит никогда. Если мы так не считаем, то могут происходить события крайне малой вероятности и наша статистика нужно выбросить и думать дальше. Примерно на этом построена методология проверки гипотез: что мы должны с чем-то согласиться и действовать дальше. Обычно согласуют некоторый уровень ошибки.

Теперь формализуем вышесказанное. Пусть $\vec{X}$ "--- наблюдение с неизвестным распределением $\Pr \in \mathcal{P}$, где $\mathcal{P}$ есть некоторое семейство распределений. Далее, возьмём подсемейство $\mathcal{P}_{0} \subset \mathcal{P}$. Поставим следующий вопрос: верно ли то, что $\Pr \in \mathcal{P}_{0}$? Ответ на этот вопрос позволяет сузить семейство распределений, что упростит анализ. Если ответ положительный, то $\mathcal{P}$ можно сузить до $\mathcal{P}_{0}$. Если же ответ отрицательный, то $\mathcal{P}$ сужается до $\mathcal{P} \setminus \mathcal{P}_{0}$. Компромисс в каком-то смысле невозможен: для получения компромисса нужно набрать ещё данных. Рассуждение за этим следующее: по текущим данным оказалось, что верна одна гипотеза, хотя кажется, что должна быть верна другая. Кажется, что выборка оказалась плохой и нужно набрать ещё данных для повторной проверки.

Обычно статистическая гипотеза (или предположение) обозначается следующим образом:
\[
	\mathrm{H}_{0} \colon \Pr \in \mathcal{P}.
\]
Что бывает ещё? В принципе, мы можем иметь не только одну гипотезу. Тогда параллельно с ней вводят альтернативу $\mathrm{H}_{1} \colon \Pr \in \mathcal{P}_{1} \subseteq \mathcal{P} \setminus \mathcal{P}_{0}$. Альтернатив может быть несколько:
\begin{align*}
	\mathrm{H}_{0} &\colon \Pr \in \mathcal{P}_{0}, \\
	\mathrm{H}_{1} &\colon \Pr \in \mathcal{P}_{1}, \\
	&\,\vdots \\
	\mathrm{H}_{k} &\colon \Pr \in \mathcal{P}_{k}.
\end{align*}
Методология метода проверки гипотез следующая. Допустим, что сравнивается пара гипотез $\mathrm{H}_{0}$ против $\mathrm{H}_{1}$. Если гипотеза $\mathrm{H}_{0}$ принимается, то есть на вопрос <<Верно ли то, что $\Pr \in \mathcal{P}_{0}$?>> даётся положительный ответ, то семейство распределений сужается до $\mathcal{P}_{0}$. Однако, если гипотезу $\mathrm{H}_{0}$ отвергают и задана альтернатива, то семейство сужают до $\mathcal{P}_{1}$. Если же альтернатив много, то вариантов постановки вопроса несколько. Первый вариант состоит в том, что все гипотезы предполагаются равноправными и потом каким-то образом выбирается одна из них. Обычно же принято действовать иначе: гипотезы перебираются по очереди, и, если гипотеза $\mathrm{H}_{i}$ принимается, то семейство сужается до $\mathcal{P}_{i}$, иначе же рассматривается гипотеза $\mathrm{H}_{i + 1}$. 

Далее возникает вопрос: какие могут быть ошибки? Например, мы можем промахнуться: например, гипотезу $\mathrm{H}_{0}$ приняли, хотя на самом деле она не верна. Такие ошибки разделяют на ошибки первого и второго рода.
\begin{definition}
	Пусть сравниваются гипотезы $\mathrm{H}_{0}$ против $\mathrm{H}_{1}$. \emph{Ошибкой первого рода} называется ситуация, когда $\mathrm{H}_{0}$ отвергли, но она была верна. Аналогично, \emph{ошибкой второго рода} называют ситуацию, когда $\mathrm{H}_{0}$ приняли, но она была не верна.
\end{definition}
И вопрос: какая из этих ошибок опаснее? Методологически считается, что ошибка первого рода опаснее. Предположим, что мы неверно отвергли $\mathrm{H}_{0}$. Тогда мы вынуждены рассматривать $\mathrm{H}_{1}$, которая заведомо неверна. В зависимости от результата проверки $\mathrm{H}_{1}$ будет либо ошибка, либо дополнительная работа в виде проверки $\mathrm{H}_{2}$ и оба варианта не вдохновляют. Тем самым будет проводиться много бесполезной работы. В случае ошибки второго рода мы принимаем $\mathrm{H}_{0}$, но она неверна. В таком случае вердикт может измениться, если добавить данных, и мы сможем двинуться в сторону чего-то более правильного. Другими словами, здесь шансы совершить много лишней работы сильно меньше.

Что это означает? То, что ошибку первого рода нужно как-то заведомо избежать, то есть вероятность того, что она произойдёт, должна быть достаточно мала (не больше $0.01$, например). Но для оценки вероятности ошибки нужно понимать, как мы будем проверять гипотезы.
\begin{definition}
	Пусть $\mathcal{X}$ "--- выборочное пространство (множество всех возможных значений наблюдений). Тогда подмножество $S \subset \mathcal{X}$ называется \emph{критерием} или \emph{критическим множеством} для проверки гипотезы $\mathrm{H}_{0}$, если правило принятия $\mathrm{H}_{0}$ выглядит так: $\mathrm{H}_{0}$ отвергается тогда и только тогда, когда $\vec{X} \in S$.
\end{definition}
По сути, $S$ есть <<плохое>> множество, и, если $\vec{X}$ попал туда, то $\mathrm{H}_{0}$ считается неправильной и выбирается альтернатива. Как только появился критерий $S$, можно ввести вероятности ошибок первого и второго рода. Но для этого нужна функция мощности.
\begin{definition}
	\emph{Функцией мощности} критерия $S$ называется 
	\[
		\beta(\QQ, S) = \QQ(\vec{X} \in S), \QQ \in \mathcal{P}.
	\]
\end{definition}
Далее возникает один момент: вероятность ошибки первого рода не является вероятностью, а является пачкой вероятностей. Аналогично со вторым родом.
\begin{definition}
	Вероятностями ошибок первого рода называется набор $\{\beta(\QQ, S) \colon \QQ \in \mathcal{P}_{0}\}$.
\end{definition}
\begin{definition}
	Вероятностями ошибок второго рода называется набор $\{1 - \beta(\QQ, S) \colon \QQ \not\in \mathcal{P}_{0}\}$.
\end{definition}
Последний вопрос: какой критерий $S$ будем подходить? Мы хотели построить очень хороший критерий в том смысле, что у него маленькие вероятности ошибок первого и второго рода. Это означает, что внутри критического множества функция мощности должна быть мала, а вне него должна быть велика. В идеале хочется получить нули, но это задача безнадёжна, и нужно на что-то соглашаться. Но на что? И как сказать, что один критерий лучше другого?

Для этого будем полагать, что вероятности ошибок первого рода ограничены сверху каким-то $\epsilon$, который называют $\emph{уровнем значимости}$. Далее, если мы зафиксировали уровень значимости, то среди всех подходящих критериев ищется тот, у которого минимальные вероятности ошибок второго рода. То, насколько получится минимизировать ошибку второго рода, сильно зависит от задачи. Хорошо себя показывают в этой истории так называемые \emph{асимптотические критерии}: в них полагается, что у выборки растущий размер. С ними получается добиться следующего: вероятность ошибки первого рода не больше, чем $\epsilon$, а вероятность второго рода стремится к нулю.